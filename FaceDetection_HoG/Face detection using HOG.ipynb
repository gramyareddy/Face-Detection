{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram of Oriented gradients\n",
    "The histogram of oriented gradients (HOG) is a feature descriptor used in computer vision and image processing for the purpose of object detection. The technique counts occurrences of gradient orientation in localized portions of an image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import data, color, feature\n",
    "import skimage.data\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from skimage import data, transform\n",
    "from sklearn.feature_extraction.image import PatchExtractor\n",
    "from itertools import chain\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"imported\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LFWdataset:\n",
    "Loader for the Labeled Faces in the Wild (LFW) people dataset\n",
    "\n",
    "This dataset is a collection of JPEG pictures of famous people collected on the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading LFW metadata: https://ndownloader.figshare.com/files/5976012\n",
      "Downloading LFW metadata: https://ndownloader.figshare.com/files/5976009\n",
      "Downloading LFW metadata: https://ndownloader.figshare.com/files/5976006\n",
      "Downloading LFW data (~200MB): https://ndownloader.figshare.com/files/5976015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13233, 62, 47)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces = fetch_lfw_people()\n",
    "positive_patches = faces.images\n",
    "positive_patches.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative Images:\n",
    "Get random images that DO NOT have a face in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "imgs_to_use = ['camera', 'text', 'coins', 'moon',\n",
    "               'page', 'clock', 'immunohistochemistry',\n",
    "               'chelsea', 'coffee', 'hubble_deep_field']\n",
    "images = [color.rgb2gray(getattr(data, name)())\n",
    "          for name in imgs_to_use]\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 62, 47)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_patches(img, N, scale=1.0, patch_size=positive_patches[0].shape):\n",
    "    extracted_patch_size = tuple((scale * np.array(patch_size)).astype(int))\n",
    "    extractor = PatchExtractor(patch_size=extracted_patch_size,\n",
    "                               max_patches=N, random_state=0)\n",
    "    patches = extractor.transform(img[np.newaxis])\n",
    "    if scale != 1:\n",
    "        patches = np.array([transform.resize(patch, patch_size)\n",
    "                            for patch in patches])\n",
    "    return patches\n",
    "\n",
    "negative_patches = np.vstack([extract_patches(im, 1000, scale)\n",
    "                              for im in images for scale in [0.5, 1.0, 2.0]])\n",
    "negative_patches.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classification:\n",
    "Now we are going to train a classifier on both these patches.\n",
    "Using LinearSVC for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43233, 1215)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array([feature.hog(im)\n",
    "                    for im in chain(positive_patches,\n",
    "                                    negative_patches)])\n",
    "y_train = np.zeros(X_train.shape[0])\n",
    "y_train[:positive_patches.shape[0]] = 1\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(C=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.4, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99005435, 0.98496588, 0.99329247, 0.98612075, 0.99097849])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(LinearSVC(C=0.4), X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Time Video Detection\n",
    "\n",
    "Design a Sliding Window that ll extract a patch from the image to classify it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(img, patch_size=positive_patches[0].shape,\n",
    "                   istep=2, jstep=2, scale=1.0):\n",
    "    Ni, Nj = (int(scale * s) for s in patch_size)\n",
    "    for i in range(0, img.shape[0] - Ni, istep):\n",
    "        for j in range(0, img.shape[1] - Ni, jstep):\n",
    "            patch = img[i:i + Ni, j:j + Nj]\n",
    "            if scale != 1:\n",
    "                patch = transform.resize(patch, patch_size)\n",
    "            yield (i, j), patch\n",
    "            \n",
    "Ni, Nj = positive_patches[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _,frame = cap.read()\n",
    "\n",
    "    frame = skimage.color.rgb2gray(frame)\n",
    "    frame = skimage.transform.rescale(frame, 0.5)\n",
    "    \n",
    "    indices, patches = zip(*sliding_window(frame))\n",
    "    \n",
    "    #  Generate hog for each patch from sliding window\n",
    "    \n",
    "    patches_hog = np.array([feature.hog(patch) for patch in patches])\n",
    "    labels = model.predict(patches_hog)\n",
    "    \n",
    "    Ni, Nj = positive_patches[0].shape\n",
    "    indices = np.array(indices)\n",
    "\n",
    "    # draw rectangles for patches which have label as 1(human face detected)\n",
    "    \n",
    "    for i, j in indices[labels == 1]:\n",
    "        cv2.rectangle(frame, (j,i),(j+Nj,i+Ni),(255,0,0),3)\n",
    "\n",
    "    \n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comments ::\n",
    "            1. FPSislow\n",
    "            2. Non msxsuppression has to be done\n",
    "            3.Many false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.13",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
